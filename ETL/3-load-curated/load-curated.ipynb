{"cells": [{"cell_type": "markdown", "id": "3838482f-07d0-4942-ab8c-352f7a30329b", "metadata": {}, "source": "### CARREGANDO OS DADOS NA CAMADA CURATED\n\nNessa etapa do processo iremos responder alguns questionamentos usando SPARK SQL, iremos criar novas tabelas com JOIN\u00b4s, agrega\u00e7\u00f5es e agrupamentos para disponilizar na camada CURATED."}, {"cell_type": "markdown", "id": "0c5d2e03-3e88-4966-ab5d-10f5296e7675", "metadata": {}, "source": "### An\u00e1lise de dados\n\nCom base na solu\u00e7\u00e3o implantada responda aos seguintes questionamentos:\n\n1.\tEscreva uma query que retorna a quantidade de linhas na tabela Sales.SalesOrderDetail pelo campo SalesOrderID, desde que tenham pelo menos tr\u00eas linhas de detalhes.\n2.\tEscreva uma query que ligue as tabelas Sales.SalesOrderDetail, Sales.SpecialOfferProduct e Production.Product e retorne os 3 produtos (Name) mais vendidos (pela soma de OrderQty), agrupados pelo n\u00famero de dias para manufatura (DaysToManufacture).\n3.\tEscreva uma query ligando as tabelas Person.Person, Sales.Customer e Sales.SalesOrderHeader de forma a obter uma lista de nomes de clientes e uma contagem de pedidos efetuados.\n4.\tEscreva uma query usando as tabelas Sales.SalesOrderHeader, Sales.SalesOrderDetail e Production.Product, de forma a obter a soma total de produtos (OrderQty) por ProductID e OrderDate.\n5.\tEscreva uma query mostrando os campos SalesOrderID, OrderDate e TotalDue da tabela Sales.SalesOrderHeader. Obtenha apenas as linhas onde a ordem tenha sido feita durante o m\u00eas de setembro/2011 e o total devido esteja acima de 1.000. Ordene pelo total devido decrescente.\n\n"}, {"cell_type": "code", "execution_count": 1, "id": "809bc3b6-1e24-49ac-9997-e77e93401d1e", "metadata": {}, "outputs": [], "source": "# Importando as bibliotecas necess\u00e1rias\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import *\nfrom pyspark.sql import functions as Func \nfrom pyspark.sql.functions import *"}, {"cell_type": "code", "execution_count": 2, "id": "b0b8697d-966f-4a20-8469-99a07dc0d9ac", "metadata": {}, "outputs": [], "source": "# Iniciando as SparkSession\nspark = SparkSession.builder.master(\"local[1]\").appName('load_curated').getOrCreate()"}, {"cell_type": "code", "execution_count": 3, "id": "3997a38c-fdfe-46e6-992a-0ecf9cee02f5", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Carregando todos os arquivos parquet da camada REFINED\ndf_person = spark.read.load('gs://bike-factory-datalake/02.REFINED/person.parquet')\ndf_product = spark.read.load('gs://bike-factory-datalake/02.REFINED/product.parquet')\ndf_customer = spark.read.load('gs://bike-factory-datalake/02.REFINED/sales.customer.parquet')\ndf_order_detail = spark.read.load('gs://bike-factory-datalake/02.REFINED/sales.salesorderdetail.parquet')\ndf_order_header = spark.read.load('gs://bike-factory-datalake/02.REFINED/sales.salesorderheader.parquet')\ndf_special_offer = spark.read.load('gs://bike-factory-datalake/02.REFINED/sales.specialofferproduct.parquet')"}, {"cell_type": "code", "execution_count": 6, "id": "4a529ee1-d678-4cbc-8159-2091049cc7b7", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Criando as tabela para usar Spark SQL\ndf_person.write.saveAsTable(\"Person_Person\")\ndf_product.write.saveAsTable(\"Production_Product\")\ndf_customer.write.saveAsTable(\"Sales_Customer\")\ndf_order_detail.write.saveAsTable(\"Sales_SalesOrderDetail\")\ndf_order_header.write.saveAsTable(\"Sales_SalesOrderHeader\")\ndf_special_offer.write.saveAsTable(\"Sales_SpecialOfferProduct\")"}, {"cell_type": "markdown", "id": "3ecfb4b4-cf01-4e9b-afc8-8d91418b06eb", "metadata": {}, "source": "1.\tEscreva uma query que retorna a quantidade de linhas na tabela Sales.SalesOrderDetail pelo campo SalesOrderID, desde que tenham pelo menos tr\u00eas linhas de detalhes."}, {"cell_type": "code", "execution_count": 7, "id": "183b6157-5b66-4ed7-bf22-4f5e252e1538", "metadata": {}, "outputs": [], "source": "question_1 = spark.sql(\n    \"\"\"SELECT SalesOrderID, count(1) as Qtdy\n        FROM Sales_SalesOrderDetail\n        GROUP BY SalesOrderID having count(SalesOrderDetailID) >= 3 order by Qtdy asc\"\"\")"}, {"cell_type": "code", "execution_count": 8, "id": "b20f3377-8b02-48c6-93d0-a37dc3799a90", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 20:==================================>                       (3 + 2) / 5]\r"}, {"name": "stdout", "output_type": "stream", "text": "+------------+----+\n|SalesOrderID|Qtdy|\n+------------+----+\n|       55999|   3|\n|       58888|   3|\n|       56018|   3|\n|       52617|   3|\n|       56993|   3|\n+------------+----+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "question_1.show(5)"}, {"cell_type": "code", "execution_count": 9, "id": "05fe7951-f227-4597-8bfc-bd7c532eb627", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "\"\"\"Agora vamos gerar um arquivo novo no formato PARQUET para disponibilizar na nossa camada CURATED.\nEsse arquivo pode ser carregado no BigQuery para gera\u00e7\u00e3o de relat\u00f3rios e insigths por\u00e9m, \no arquivo que j\u00e1 se encontra na camara REFINED j\u00e1 poderia ser carregado no BigQuery para rodar queries diretamente nele.\"\"\"\nquestion_1.write.mode(\"overwrite\").save(\"gs://bike-factory-datalake/03.CURATED/question_1\")"}, {"cell_type": "markdown", "id": "584460b5-56e3-47d8-8a2b-8d7fe5907ff1", "metadata": {}, "source": "2.\tEscreva uma query que ligue as tabelas Sales.SalesOrderDetail, Sales.SpecialOfferProduct e Production.Product e retorne os 3 produtos (Name) mais vendidos (pela soma de OrderQty), agrupados pelo n\u00famero de dias para manufatura (DaysToManufacture).\n"}, {"cell_type": "code", "execution_count": 10, "id": "d5ef47c4-5b72-48fc-b803-fc093c8b957f", "metadata": {}, "outputs": [], "source": "question_2 = spark.sql(\"\"\"\n                       SELECT PP.Name, PP.DaysToManufacture, sum(SOD.orderqty) as SumOrderQty\n                       FROM Production_Product as PP\n                       INNER JOIN Sales_SpecialOfferProduct as SOP on SOP.ProductID = PP.ProductID\n                       INNER JOIN Sales_SalesOrderDetail as SOD on SOD.ProductID = PP.ProductID\n                       GROUP BY PP.Name, PP.DaysToManufacture\n                       ORDER BY 3 desc\"\"\")"}, {"cell_type": "code", "execution_count": 11, "id": "69f8414e-7007-49eb-a996-2c55f50b4750", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+-----------------+-----------+\n|                Name|DaysToManufacture|SumOrderQty|\n+--------------------+-----------------+-----------+\n|Sport-100 Helmet,...|                0|      33715|\n|        AWC Logo Cap|                0|      33244|\n|Sport-100 Helmet,...|                0|      32660|\n+--------------------+-----------------+-----------+\nonly showing top 3 rows\n\n"}], "source": "# Mostrando apenas o 3 produtos mais vendidos\nquestion_2.show(3)"}, {"cell_type": "code", "execution_count": 12, "id": "6c1384dc-072a-497f-9f23-f76a7ffc82fd", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Vamos gravar essa tabela completa com os JOIN\u00b4s em uma nova tabela na nossa camada CURATED.\nquestion_2.write.mode(\"overwrite\").save(\"gs://bike-factory-datalake/03.CURATED/question_2\")"}, {"cell_type": "markdown", "id": "91c226d5-ef19-4054-830e-e49e525e81ba", "metadata": {}, "source": "3.\tEscreva uma query ligando as tabelas Person.Person, Sales.Customer e Sales.SalesOrderHeader de forma a obter uma lista de nomes de clientes e uma contagem de pedidos efetuados.\n"}, {"cell_type": "code", "execution_count": 13, "id": "337af857-5dc4-40f3-8c02-b4c080c0d7fe", "metadata": {}, "outputs": [], "source": "# Ao avaliar o modelo relacional disponibilizada, o mesmo informa que a FK da tabela Sales.Customer na Person.Person \u00e9 o campo PersonID, por\u00e9m essa campo n\u00e3o existe.\n# Contudo, foi poss\u00edvel fazer o relacionamento entre elas usando o campo BusinessEntityID da tabela Person.Person.\nquestion_3 = spark.sql(\"\"\"\n                        SELECT PE.CompleteName, count(SOH.SalesOrderID) as OrderQtdy\n                        FROM Sales_SalesOrderHeader as SOH\n                        INNER JOIN Sales_Customer as C on C.CustomerID = SOH.CustomerID\n                        INNER JOIN Person_Person as PE on PE.BusinessEntityID = C.CustomerID\n                        GROUP BY PE.CompleteName ORDER BY PE.CompleteName\"\"\") \n"}, {"cell_type": "code", "execution_count": 14, "id": "1d903272-3441-46e1-bb3d-53ce3de83229", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-----------------+---------+\n|     CompleteName|OrderQtdy|\n+-----------------+---------+\n|  Aaron  Edwards |        3|\n|Aaron  Hernandez |        2|\n|     Aaron  Hill |        2|\n|  Aaron  Roberts |        2|\n|   Aaron A Allen |        1|\n|   Aaron B Adams |        1|\n|Aaron C Campbell |        2|\n|   Aaron C Scott |        2|\n|   Aaron E Baker |        1|\n|   Aaron E Evans |        3|\n|  Aaron J Carter |        2|\n|Aaron J McDonald |        1|\n|    Aaron K Hall |        1|\n|    Aaron L King |        2|\n|   Aaron L Perez |        1|\n|  Aaron L Wright |        1|\n|Aaron M Gonzalez |        2|\n|   Aaron M Young |        1|\n| Aaron P Collins |        4|\n|   Aaron R Green |        1|\n+-----------------+---------+\nonly showing top 20 rows\n\n"}], "source": "question_3.show()"}, {"cell_type": "code", "execution_count": 15, "id": "0c2f7317-02a6-4857-897e-fba6c1657a4a", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Persistindo os dados dessa nova tabela com os JOIN\u00b4s na camada CURATED\nquestion_3.write.mode(\"overwrite\").save(\"gs://bike-factory-datalake/03.CURATED/question_3\")"}, {"cell_type": "markdown", "id": "80e65990-9eb4-4d69-9918-afd4d561204b", "metadata": {}, "source": "4.\tEscreva uma query usando as tabelas Sales.SalesOrderHeader, Sales.SalesOrderDetail e Production.Product, de forma a obter a soma total de produtos (OrderQty) por ProductID e OrderDate."}, {"cell_type": "code", "execution_count": 16, "id": "45e91d6e-1518-4798-b7a5-398699eba384", "metadata": {}, "outputs": [], "source": "question_4 = spark.sql(\"\"\"\n                       SELECT SOD.ProductID ,SOH.OrderDate,sum(SOD.OrderQty) as OrderQty\n                        FROM Sales_SalesOrderHeader as SOH\n                        INNER JOIN Sales_SalesOrderDetail as SOD on SOD.SalesOrderID  = SOH.SalesOrderID\n                        INNER JOIN Production_Product as PP on PP.ProductID = SOD.ProductID\n                        GROUP BY SOD.ProductID, SOH.OrderDate\n                        ORDER BY OrderDate\"\"\")"}, {"cell_type": "code", "execution_count": 17, "id": "e84d0272-5a2e-4707-88f9-fae8261a0e97", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 61:=============================>                            (1 + 1) / 2]\r"}, {"name": "stdout", "output_type": "stream", "text": "+---------+-------------------+--------+\n|ProductID|          OrderDate|OrderQty|\n+---------+-------------------+--------+\n|      773|2011-05-31 00:00:00|      17|\n|      776|2011-05-31 00:00:00|      16|\n|      777|2011-05-31 00:00:00|      23|\n|      732|2011-05-31 00:00:00|      16|\n|      716|2011-05-31 00:00:00|      19|\n|      772|2011-05-31 00:00:00|       5|\n|      743|2011-05-31 00:00:00|       1|\n|      770|2011-05-31 00:00:00|      29|\n|      753|2011-05-31 00:00:00|      14|\n|      710|2011-05-31 00:00:00|       5|\n|      729|2011-05-31 00:00:00|      16|\n|      747|2011-05-31 00:00:00|       4|\n|      748|2011-05-31 00:00:00|       2|\n|      764|2011-05-31 00:00:00|      14|\n|      758|2011-05-31 00:00:00|      46|\n|      775|2011-05-31 00:00:00|      22|\n|      715|2011-05-31 00:00:00|      49|\n|      762|2011-05-31 00:00:00|      44|\n|      767|2011-05-31 00:00:00|       1|\n|      707|2011-05-31 00:00:00|      24|\n+---------+-------------------+--------+\nonly showing top 20 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "question_4.show()"}, {"cell_type": "code", "execution_count": 18, "id": "0c464e89-cf3b-4084-a4fd-46679d473474", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Persistindo os dados dessa nova tabela com os JOIN\u00b4s na camada CURATED\nquestion_4.write.mode(\"overwrite\").save(\"gs://bike-factory-datalake/03.CURATED/question_4\")"}, {"cell_type": "markdown", "id": "ac1e6ae5-5ba0-4adc-b77a-a0e1ea1dd34a", "metadata": {}, "source": "5.\tEscreva uma query mostrando os campos SalesOrderID, OrderDate e TotalDue da tabela Sales.SalesOrderHeader. Obtenha apenas as linhas onde a ordem tenha sido feita durante o m\u00eas de setembro/2011 e o total devido esteja acima de 1.000. Ordene pelo total devido decrescente.\n"}, {"cell_type": "code", "execution_count": 19, "id": "9fd0f0d9-a140-4a3e-a716-13d5ff02c381", "metadata": {}, "outputs": [], "source": "question_5 = spark.sql(\"\"\"\n                       SELECT SalesOrderID, OrderDate, TotalDue\n                        FROM Sales_SalesOrderHeader\n                        WHERE OrderDate BETWEEN '2011-09-01' AND '2011-09-30'\n                        AND TotalDue > 1000\n                        ORDER BY TotalDue desc\"\"\")"}, {"cell_type": "code", "execution_count": 20, "id": "c2faa509-fc99-493f-9907-795dbc32ab19", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+------------+-------------------+---------+\n|SalesOrderID|          OrderDate| TotalDue|\n+------------+-------------------+---------+\n|       44348|2011-09-07 00:00:00|3953.9884|\n|       44372|2011-09-09 00:00:00|3953.9884|\n|       44349|2011-09-07 00:00:00|3953.9884|\n|       44350|2011-09-07 00:00:00|3953.9884|\n|       44371|2011-09-09 00:00:00|3953.9884|\n|       44351|2011-09-07 00:00:00|3953.9884|\n|       44328|2011-09-02 00:00:00|3953.9884|\n|       44352|2011-09-07 00:00:00|3953.9884|\n|       44330|2011-09-02 00:00:00|3953.9884|\n|       44332|2011-09-03 00:00:00|3953.9884|\n|       44370|2011-09-09 00:00:00|3953.9884|\n|       44357|2011-09-07 00:00:00|3953.9884|\n|       44338|2011-09-04 00:00:00|3953.9884|\n|       44358|2011-09-07 00:00:00|3953.9884|\n|       44340|2011-09-04 00:00:00|3953.9884|\n|       44359|2011-09-08 00:00:00|3953.9884|\n|       44347|2011-09-06 00:00:00|3953.9884|\n|       44324|2011-09-01 00:00:00|3953.9884|\n|       44326|2011-09-01 00:00:00|3953.9884|\n|       44327|2011-09-02 00:00:00|3953.9884|\n+------------+-------------------+---------+\nonly showing top 20 rows\n\n"}], "source": "question_5.show()"}, {"cell_type": "code", "execution_count": 21, "id": "053b527c-04a1-432f-a49c-673dcec7e542", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Persistindo os dados dessa nova tabela com os JOIN\u00b4s na camada CURATED\nquestion_5.write.mode(\"overwrite\").save(\"gs://bike-factory-datalake/03.CURATED/question_5\")"}, {"cell_type": "code", "execution_count": 22, "id": "126a1ce6-37a0-4af7-aa5a-ad5898f33528", "metadata": {}, "outputs": [{"data": {"text/plain": "DataFrame[]"}, "execution_count": 22, "metadata": {}, "output_type": "execute_result"}], "source": "spark.sql(\"DROP TABLE Person_Person\")\nspark.sql(\"DROP TABLE Production_Product\")\nspark.sql(\"DROP TABLE Sales_Customer\")\nspark.sql(\"DROP TABLE Sales_SalesOrderDetail\")\nspark.sql(\"DROP TABLE Sales_SalesOrderHeader\")\nspark.sql(\"DROP TABLE Sales_SpecialOfferProduct\")"}, {"cell_type": "code", "execution_count": 23, "id": "e654303e-e029-4527-be3c-7056745416f4", "metadata": {}, "outputs": [], "source": "spark.stop()"}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.12"}}, "nbformat": 4, "nbformat_minor": 5}